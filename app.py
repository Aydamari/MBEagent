import streamlit as st
import google.generativeai as genai
import PyPDF2 as pdf
import os

# --- FUN√á√ïES AUXILIARES ---

@st.cache_data  # Otimiza√ß√£o: L√™ o prompt do arquivo apenas uma vez
def load_prompt(file_path):
    """L√™ e retorna o conte√∫do de um arquivo de texto."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        st.error(f"ERRO: O arquivo de prompt '{file_path}' n√£o foi encontrado. Certifique-se de que ele est√° no mesmo diret√≥rio que o app.py.")
        return None

def extract_text_from_pdf(uploaded_file):
    """Extrai texto de um arquivo PDF enviado."""
    if uploaded_file is not None:
        try:
            pdf_reader = pdf.PdfReader(uploaded_file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()
            return text
        except Exception as e:
            st.error(f"Erro ao ler o PDF: {e}")
            return None
    return None


# --- CONFIGURA√á√ÉO INICIAL E CARREGAMENTO DE DADOS ---

# Carrega o prompt mestre a partir do arquivo externo
PROMPT_MESTRE = load_prompt("master_prompt.txt")

# Configura a API do Google (para deploy no Streamlit Cloud)
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=API_KEY)
except (KeyError, FileNotFoundError):
    st.error("Chave de API do Google n√£o configurada! Adicione-a nos segredos (secrets) do seu app no Streamlit Cloud.")
    st.stop()


# --- INTERFACE DO USU√ÅRIO (UI) ---

st.set_page_config(page_title="Analisador de Artigos MBE/PBE", layout="wide")
st.header("üî¨ Analisador de Artigos Cient√≠ficos MBE/PBE")
st.caption("Desenvolvido por Igor Eckert & Aydamari Faria-Jr")

# Barra Lateral com Configura√ß√µes
st.sidebar.title("Configura√ß√µes")

# Dicion√°rio que mapeia nomes amig√°veis para os nomes de API corretos
model_mapping = {
    "Gemini 2.0 Flash (Padr√£o)": "gemini-2.0-flash",
    "Gemma 3 27B": "gemma-3-27b-it",
    "Gemini 2.5 Pro (Em breve)": "disabled"
}
model_options = list(model_mapping.keys())

# Seletor de modelo
selected_model_name = st.sidebar.selectbox(
    "Escolha o modelo de IA:",
    options=model_options,
    index=0 # Define o modelo padr√£o
)
st.sidebar.info("A sele√ß√£o do modelo impacta a velocidade e a qualidade da an√°lise. O Gemini 2.5 Pro ser√° habilitado no futuro.")

# Interface Principal
prompt_usuario = st.text_area(
    "Instru√ß√µes Adicionais (Opcional):",
    height=100,
    placeholder="O prompt principal j√° est√° configurado. Use este campo para focar a an√°lise em um ponto espec√≠fico. Ex: 'Foque apenas na an√°lise de vi√©s de sele√ß√£o' ou 'Compare os resultados com o estudo de Smith et al. 2022'."
)
uploaded_file = st.file_uploader("Fa√ßa o upload do seu artigo em PDF aqui:", type=["pdf"])
submit_button = st.button("Analisar Artigo")


# --- L√ìGICA PRINCIPAL ---

# S√≥ executa se o prompt mestre foi carregado com sucesso
if PROMPT_MESTRE and submit_button:
    actual_model_id = model_mapping[selected_model_name]

    # Valida√ß√µes de entrada
    if actual_model_id == "disabled":
        st.warning("O modelo Gemini 2.5 Pro ainda n√£o est√° dispon√≠vel. Por favor, selecione outro modelo.")
    elif uploaded_file is None:
        st.warning("Por favor, fa√ßa o upload de um arquivo PDF antes de analisar.")
    else:
        # Processamento
        with st.spinner("Extraindo texto do PDF..."):
            texto_extraido = extract_text_from_pdf(uploaded_file)

        if texto_extraido:
            st.info(f"Texto extra√≠do com sucesso! Enviando para o modelo: **{selected_model_name}**")

            prompt_final = f"""
            {PROMPT_MESTRE}
            ---
            INSTRU√á√ÉO ADICIONAL DO USU√ÅRIO (se houver, deve complementar a tarefa principal):
            {prompt_usuario if prompt_usuario else "Nenhuma instru√ß√£o adicional fornecida."}
            ---
            CONTE√öDO DO ARTIGO CIENT√çFICO PARA AN√ÅLISE:
            {texto_extraido}
            """

            try:
                with st.spinner(f"O modelo '{selected_model_name}' est√° processando a an√°lise cr√≠tica..."):
                    model = genai.GenerativeModel(actual_model_id)
                    response = model.generate_content(prompt_final)
                
                st.subheader("Resultado da An√°lise Cr√≠tica:")
                st.markdown(response.text)

            except Exception as e:
                st.error(f"Ocorreu um erro ao chamar a API do Gemini: {e}")
